import os
import requests
from langchain.schema import Document

def agent_team2_web_search(state: dict, max_results=5) -> dict:
    query = state.get("rag_query", "").strip()
    new_state = state.copy()

    if not query:
        print("âš ï¸ rag_query ì—†ìŒ")
        new_state["web_docs"] = []
        return new_state

    api_key = os.getenv("SERPAPI_API_KEY")  # í™˜ê²½ë³€ìˆ˜ì— SerpAPI í‚¤ ì €ì¥
    endpoint = "https://serpapi.com/search"
    params = {
        "engine": "google_light",
        "q": query,
        "api_key": api_key
    }

    try:
        response = requests.get(endpoint, params=params)
        response.raise_for_status()
        data = response.json()

        docs = []

        # 1. Answer box ìš°ì„  ì €ì¥ (ì˜ˆ: 'answer_box', 'knowledge_graph' ë“±)
        answer_box = data.get("answer_box")
        if answer_box:
            answer = answer_box.get("answer") or answer_box.get("snippet") or answer_box.get("highlighted") or ""
            if answer:
                docs.append(Document(
                    page_content=answer.strip(),
                    metadata={"source": "answer_box", "title": answer_box.get("title", "")}
                ))

        # 2. Knowledge Graph
        knowledge_graph = data.get("knowledge_graph")
        if knowledge_graph:
            desc = knowledge_graph.get("description") or ""
            if desc:
                docs.append(Document(
                    page_content=desc.strip(),
                    metadata={"source": "knowledge_graph", "title": knowledge_graph.get("title", "")}
                ))

        # 3. Organic Results
        organic_results = data.get("organic_results", [])
        for item in organic_results[:max_results - len(docs)]:
            snippet = item.get("snippet", "")
            if snippet:
                docs.append(Document(
                    page_content=snippet.strip(),
                    metadata={"source": item.get("link", ""), "title": item.get("title", "")}
                ))

        new_state["web_docs"] = docs
        # docs ì¶œë ¥
        if docs:
            print(f"ğŸ” {len(docs)}ê°œì˜ ì›¹ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼:")
            for doc in docs:
                print(f"- {doc.metadata.get('title', 'ì œëª© ì—†ìŒ')}: {doc.page_content[:100]}...")  # ë‚´ìš© ì¼ë¶€ ì¶œë ¥
        else:
            print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return new_state

    except Exception as e:
        print(f"âŒ SerpAPI ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        new_state["web_docs"] = []
        return new_state
