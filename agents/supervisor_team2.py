import json
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from agents.team2_rag_agent import agent_team2_rag_search
from agents.team2_web_agent import agent_team2_web_search
from langchain_core.runnables import RunnableLambda

PROMPT = """
[ì§ˆë¬¸ ìš”ì•½]
{q_en_transformed}

[RAG Query]
{rag_query}

[ê²€ìƒ‰ëœ ë¬¸ì„œ]
{combined_docs}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì„¸ìš”:
1. semantic_relevance (0~1): ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ë§ëŠ”ê°€?
2. coverage (0~1): ë¬¸ì„œê°€ ì¶©ë¶„íˆ ë‹µì„ ì»¤ë²„í•˜ëŠ”ê°€?
3. expertise_score = (semantic_relevance + coverage) / 2

ê²°ê³¼ë¥¼ ì•„ë˜ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "expertise_score": float
}}
"""

def evaluate_docs(docs, q_summary, query, llm, chain):
    if not docs:
        return 0.0
    from langchain.schema import Document
    filtered_docs = []
    for doc in docs:
        if hasattr(doc, "page_content"):
            filtered_docs.append(doc)
        elif isinstance(doc, str) and doc.strip():
            filtered_docs.append(Document(page_content=doc))
    if not filtered_docs:
        return 0.0
    combined_docs = "\n\n".join([doc.page_content for doc in filtered_docs])
    try:
        result = chain.invoke({
            "q_en_transformed": q_summary,
            "rag_query": query,
            "combined_docs": combined_docs
        })
        parsed = json.loads(result.content)
        return parsed.get("expertise_score", 0.0)
    except Exception as e:
        print(f"âŒ í‰ê°€ ì˜¤ë¥˜: {e}")
        return 0.0

def supervisor_team2(state: dict) -> dict:
    print(f"ğŸ” Team 2 Supervisor ì‹œì‘")
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)
    prompt = PromptTemplate.from_template(PROMPT)
    chain = prompt | llm

    q_summary = state.get("q_en_transformed", "")
    query = state.get("rag_query", "")

    max_attempts = 2

    # === RAG íƒìƒ‰ ìµœëŒ€ 2íšŒ ===
    for attempt in range(max_attempts):
        print(f"ğŸ” RAG ë¬¸ì„œ ê²€ìƒ‰ ({attempt+1}ì°¨)")
        state = RunnableLambda(agent_team2_rag_search).invoke(state)
        docs = state.get("rag_docs", [])
        score = evaluate_docs(docs, q_summary, query, llm, chain)
        if score >= 0.5:
            print(f"âœ… Team 2 í†µê³¼ (RAG {attempt+1}ì°¨, score={score:.2f})")
            state["status"]["team2"] = "pass"
            return state
        else:
            print(f"ğŸ” RAG {attempt+1}ì°¨ ì‹¤íŒ¨ (score={score:.2f})")

    # === WEB íƒìƒ‰ ìµœëŒ€ 2íšŒ ===
    for attempt in range(max_attempts):
        print(f"ğŸŒ WEB ë¬¸ì„œ ê²€ìƒ‰ ({attempt+1}ì°¨)")
        state = RunnableLambda(agent_team2_web_search).invoke(state)
        docs = state.get("web_docs", [])
        score = evaluate_docs(docs, q_summary, query, llm, chain)
        if score >= 0.5:
            print(f"âœ… Team 2 í†µê³¼ (WEB {attempt+1}ì°¨, score={score:.2f})")
            state["status"]["team2"] = "pass"
            return state
        else:
            print(f"ğŸ” WEB {attempt+1}ì°¨ ì‹¤íŒ¨ (score={score:.2f})")

    # === ëª¨ë“  ì‹œë„ ì‹¤íŒ¨ ===
    print("âŒ Team 2 ìµœì¢… ì‹¤íŒ¨")
    state["status"]["team2"] = "fail"
    return state
