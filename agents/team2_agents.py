# agents/team2_agents.py

import json
import uuid
from typing import List, Dict, Any

from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import ToolMessage
from pydantic import BaseModel, Field

import config
from state import AgentState
from utility_tools import vector_store_rag_search, deep_research_web_search, format_docs

THRESHOLD = 0.7  # í†µê³¼ ì„ê³„ì¹˜(ê¸°ì¡´ ê¸°ì¤€)

# --- ë‹¨ì¼ ë¬¸ì„œ í‰ê°€ ìŠ¤í‚¤ë§ˆ ---
class DocEvaluationResult(BaseModel):
    semantic_relevance: float = Field(ge=0.0, le=1.0, description="ë¬¸ì„œê°€ ì§ˆë¬¸ ì˜ë„ì™€ ì œì•½ì— ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ [0,1]")
    is_detailed: float = Field(ge=0.0, le=1.0, description="ë¬¸ì„œê°€ ì¶©ë¶„íˆ êµ¬ì²´ì ì´ê³  ì„¸ë¶€ì ì¸ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ì ìˆ˜ [0,1]")
    error_message: str = ""

def _get_query_from_history(state: AgentState) -> str:
    for msg in reversed(state['messages']):
        if isinstance(msg, ToolMessage) and msg.name == "team1_evaluator":
            return msg.additional_kwargs.get("best_rag_query", "")
    return ""

def _get_refined_question_from_history(state: AgentState) -> str:
    for msg in reversed(state['messages']):
        if isinstance(msg, ToolMessage) and msg.name == "team1_evaluator":
            return msg.additional_kwargs.get("q_en_transformed", "")
    return ""

# --- Node 1: RAG ê²€ìƒ‰(10ê±´ í™•ë³´) ---
def rag_search(state: AgentState) -> Dict[str, Any]:
    print("--- AGENT: Team 2 (RAG ê²€ìƒ‰) ì‹¤í–‰ ---")
    rag_query = _get_query_from_history(state)
    if not rag_query:
        return {"messages": [ToolMessage(content="fail: RAG ì¿¼ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", name="rag_search", tool_call_id=str(uuid.uuid4()))]}

    try:
        rag_docs = vector_store_rag_search.func(rag_query, top_k=5, rerank_k=5)  # 5ê±´ í‰ê°€ë¥¼ ìœ„í•´ ì¡°ì •
        return {
            "messages": [
                ToolMessage(
                    content=format_docs(rag_docs),
                    name="rag_search_result",
                    tool_call_id=str(uuid.uuid4()),
                    additional_kwargs={"source_docs": rag_docs}
                )
            ],
            # Team2 ì‚¬ì´í´ ì‹œì‘: ëˆ„ì  ë²„í‚· ì´ˆê¸°í™”
            "rag_docs": [],
            "web_docs": [],
        }
    except Exception as e:
        print(f"âŒ Team 2 (RAG ê²€ìƒ‰) ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"messages": [ToolMessage(content=f"fail: RAG ê²€ìƒ‰ ì˜¤ë¥˜ - {e}", name="rag_search", tool_call_id=str(uuid.uuid4()))]}

# --- Node 2: ì›¹ ê²€ìƒ‰(3ê±´ ë‹¨ìœ„) ---
def web_search(state: AgentState) -> Dict[str, Any]:
    print("--- AGENT: Team 2 (ì›¹ ê²€ìƒ‰) ì‹¤í–‰ ---")
    rag_query = _get_query_from_history(state)
    try:
        web_docs = deep_research_web_search.func(rag_query, max_results=3)
        return {
            "messages": [
                ToolMessage(
                    content=format_docs(web_docs),
                    name="web_search_result",
                    tool_call_id=str(uuid.uuid4()),
                    additional_kwargs={"source_docs": web_docs}
                )
            ]
        }
    except Exception as e:
        print(f"âŒ Team 2 (ì›¹ ê²€ìƒ‰) ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"messages": [ToolMessage(content=f"fail: ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜ - {e}", name="web_search", tool_call_id=str(uuid.uuid4()))]}

# --- Node 3: ë¬¸ì„œ í‰ê°€(ë¬¸ì„œë³„ ìŠ¤ì½”ì–´ë§ & ì†ŒìŠ¤ë³„ ëˆ„ì ) ---
def evaluate_documents(state: AgentState) -> Dict[str, Any]:
    print("--- AGENT: Team 2 (ë¬¸ì„œ í‰ê°€) ì‹¤í–‰ ---")

    last_message = state['messages'][-1]
    docs_to_evaluate = last_message.additional_kwargs.get("source_docs", [])
    source = "web" if last_message.name == "web_search_result" else "rag"

    # ëˆ„ì  ë²„í‚· ë¡œë“œ
    rag_acc = list(state.get("rag_docs", []))
    web_acc = list(state.get("web_docs", []))

    # í‰ê°€í•  ëŒ€ìƒì´ ì—†ìœ¼ë©´ ì†ŒìŠ¤ë³„ ê¸°ë³¸ ë¶„ê¸°
    if not docs_to_evaluate:
        decision = "fallback_to_web" if source == "rag" else "retry_web"
        return {
            "messages": [ToolMessage(content=decision, name="team2_evaluator", tool_call_id=str(uuid.uuid4()))],
            "rag_docs": rag_acc,
            "web_docs": web_acc,
        }

    q_en_transformed = _get_refined_question_from_history(state)
    rag_query = _get_query_from_history(state)

    # ë‹¨ì¼ ë¬¸ì„œ í‰ê°€ ì²´ì¸
    parser = JsonOutputParser(p_object=DocEvaluationResult)
    single_doc_prompt = PromptTemplate.from_template("""
You are the Team2 Supervisor evaluator. Given the question summary and retrieved document,
decide whether the document is good enough to support answering the question.

[Question Summary]
{q_en_transformed}

[RAG Query]
{rag_query}

[Document]
{doc_text}

Return JSON ONLY with the following fields:
- semantic_relevance (float in [0,1]): Do the docs match the user's intent and constraints?
- is_detailed (float in [0,1]): Do the docs collectively contain enough specifics to answer the question reliably?
- error_message (str): If anything is wrong (empty/irrelevant/too generic/duplicated), write a short Korean message; else "".

Output schema:
{schema}
""").partial(schema=parser.get_format_instructions())
    llm = ChatOpenAI(
        model=config.LLM_MODEL_TEAM2_EVAL,
        temperature=0.0,
        model_kwargs={"response_format": {"type": "json_object"}}
    )
    chain = single_doc_prompt | llm | parser

    accepted: List[Any] = []
    rejected: List[Any] = []

    for doc in docs_to_evaluate:
        try:
            preview = (getattr(doc, "page_content", "") or "")[:4000]
            result_dict = chain.invoke({"q_en_transformed": q_en_transformed, "rag_query": rag_query, "doc_text": preview})
            r = DocEvaluationResult.model_validate(result_dict)
            is_pass = (r.semantic_relevance >= THRESHOLD) and (r.is_detailed >= THRESHOLD)
            if is_pass:
                accepted.append(doc)
            else:
                rejected.append({"reason": r.error_message, "snippet": preview[:300]})
        except Exception as e:
            rejected.append({"reason": f"LLM ì˜¤ë¥˜: {e}", "snippet": (getattr(doc, "page_content", "") or "")[:300]})

    # ì†ŒìŠ¤ë³„ ëˆ„ì 
    if accepted:
        if source == "rag":
            rag_acc += accepted
        else:
            web_acc += accepted

    total = len(rag_acc) + len(web_acc)
    print(f"ğŸ“Š í‰ê°€ ê²°ê³¼: RAG ëˆ„ì  {len(rag_acc)} / WEB ëˆ„ì  {len(web_acc)} (í•©ê³„ {total}, ëª©í‘œ â‰¥ 3)")

    if total >= 3:
        # í†µê³¼: Team3ë¡œ ì§„í–‰
        combined = rag_acc + web_acc  # rag ìš°ì„  ìˆœì„œ ìœ ì§€
        return {
            "messages": [
                ToolMessage(
                    content="pass",
                    name="team2_evaluator",
                    tool_call_id=str(uuid.uuid4()),
                    additional_kwargs={
                        "source": source,
                        "accepted_rag": len(rag_acc),
                        "accepted_web": len(web_acc),
                        # Team3 í˜¸í™˜ì„±: ë‘˜ ë‹¤ ì „ë‹¬ + í•©ë³¸ë„ í•¨ê»˜
                        "rag_docs": rag_acc,
                        "web_docs": web_acc,
                        "retrieved_docs": combined,
                    }
                )
            ],
            "rag_docs": rag_acc,
            "web_docs": web_acc,
        }
    else:
        # ë¶€ì¡±: RAG ì´í›„ë©´ ì›¹ìœ¼ë¡œ, ì›¹ ì´í›„ë©´ ì›¹ ì¬ì‹œë„
        decision = "fallback_to_web" if source == "rag" else "retry_web"
        return {
            "messages": [
                ToolMessage(
                    content=decision,
                    name="team2_evaluator",
                    tool_call_id=str(uuid.uuid4()),
                    additional_kwargs={
                        "source": source,
                        "accepted_rag": len(rag_acc),
                        "accepted_web": len(web_acc),
                        "current_total": total,
                    }
                )
            ],
            "rag_docs": rag_acc,
            "web_docs": web_acc,
        }
