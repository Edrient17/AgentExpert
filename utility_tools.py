# utility_tools.py

import os
import requests
import torch
from typing import List

from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI
from transformers import AutoTokenizer, AutoModelForSequenceClassification

import config

# --- Reranker ëª¨ë¸ ì „ì—­ ë¡œë“œ ---
print("ReRanker ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
try:
    rerank_tokenizer = AutoTokenizer.from_pretrained(config.RERANKER_MODEL)
    rerank_model = AutoModelForSequenceClassification.from_pretrained(config.RERANKER_MODEL)
    print("ReRanker ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
except Exception as e:
    print(f"ReRanker ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    rerank_model = None

def format_docs(docs: List[Document], max_chars: int = 15000) -> str:
    """
    LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ LLM í”„ë¡¬í”„íŠ¸ì— ì‚½ì…í•˜ê¸° ì¢‹ì€ ë‹¨ì¼ ë¬¸ìì—´ë¡œ ê²°í•©í•©ë‹ˆë‹¤.
    """
    contents = [doc.page_content.strip() for doc in docs if isinstance(doc, Document) and doc.page_content]
    if not contents:
        return "[NO CONTENT]"

    joined_content = "\n\n---\n\n".join(contents)
    return joined_content[:max_chars] + "\n\n...[ë‚´ìš© ì¼ë¶€ ìƒëµ]..." if len(joined_content) > max_chars else joined_content

# --- Tool 1: Vector Store RAG ê²€ìƒ‰ ---
@tool
def vector_store_rag_search(query: str, top_k: int = 10, rerank_k: int = 3) -> List[Document]:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ì„ ë°›ì•„ ë¡œì»¬ Vector Store(FAISS)ì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ê³ ,
    ì •í™•ë„ë¥¼ ë†’ì´ê¸° ìœ„í•´ ë¦¬ë­í‚¹(reranking)ì„ ìˆ˜í–‰í•œ í›„ ìƒìœ„ ë¬¸ì„œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë‚´ë¶€ ì§€ì‹ ë² ì´ìŠ¤ì—ì„œ ì •ë³´ë¥¼ ì°¾ì•„ì•¼ í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ RAG Tool ì‹¤í–‰: '{query}'")
    if not query: return []
    try:
        embedding = HuggingFaceEmbeddings(model_name=config.EMBEDDING_MODEL)
        db = FAISS.load_local(config.VECTOR_STORE_PATH, embedding, allow_dangerous_deserialization=True)
        candidate_docs = db.similarity_search(query, k=top_k)

        if rerank_model and candidate_docs:
            pairs = [(query, doc.page_content) for doc in candidate_docs]
            inputs = rerank_tokenizer(pairs, padding=True, truncation=True, return_tensors="pt", max_length=512)
            with torch.no_grad():
                scores = rerank_model(**inputs).logits.squeeze().tolist()
            scored_docs = sorted(zip(scores, candidate_docs), key=lambda x: x[0], reverse=True)
            return [doc for score, doc in scored_docs[:rerank_k]]
        return candidate_docs[:rerank_k]
    except Exception as e:
        print(f"âŒ RAG Tool ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# --- Tool 2: OpenAI ì›¹ ê²€ìƒ‰ ---

# --- Pydantic ìŠ¤í‚¤ë§ˆ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ êµ¬ì¡°í™”) ---
class SearchResult(BaseModel):
    """A single search result with its title, URL, and comprehensive summary."""
    title: str = Field(description="The title of the search result.")
    url: str = Field(description="The URL of the search result.")
    summary: str = Field(description="A detailed and comprehensive summary of the search result's content, answering the user's query.")

class SearchResults(BaseModel):
    """A list of search results."""
    results: List[SearchResult]

@tool
def deep_research_web_search(query: str, max_results: int = 3) -> List[Document]:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸(query)ì— ëŒ€í•´ gpt-4.1 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì‹¬ì¸µì ì¸ ì›¹ ë¦¬ì„œì¹˜ë¥¼ ìˆ˜í–‰í•˜ê³ ,
    ê·¸ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”ëœ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    ìµœì‹  ì •ë³´ë‚˜ ì™¸ë¶€ì˜ ê¹Šì´ ìˆëŠ” ì§€ì‹ì´ í•„ìš”í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    print(f"ğŸ› ï¸ Deep Research Tool ì‹¤í–‰: '{query}'")
    if not query: return []

    try:
        # LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì •
        llm = ChatOpenAI(model="gpt-4.1", temperature=0)
        structured_llm = llm.with_structured_output(SearchResults)
        
        prompt = PromptTemplate.from_template(
            """You are an expert web researcher. Your task is to conduct a thorough and objective web search to answer the user's query.
            
            Please find {max_results} distinct, detailed, and non-overlapping results that directly address the following query: '{query}'
            
            For each result, provide a clear title, the source URL, and a comprehensive summary. Ensure the summary is detailed enough to be useful on its own."""
        )

        # ì²´ì¸ ì‹¤í–‰
        chain = prompt | structured_llm
        response = chain.invoke({"query": query, "max_results": max_results})

        # ê²°ê³¼ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜
        docs = []
        if response and response.results:
            for result in response.results:
                doc = Document(
                    page_content=f"Title: {result.title}\nSummary: {result.summary}",
                    metadata={"source": result.url, "title": result.title}
                )
                docs.append(doc)
        
        return docs

    except Exception as e:
        print(f"âŒ Deep Research Tool ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []