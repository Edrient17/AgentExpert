# graphs/super_graph.py

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END

import config
from state import GlobalState

def retrieval_necessity_router(state: GlobalState) -> str:
    """
    Team 1 ì™„ë£Œ í›„, LLMì„ ì´ìš©í•´ Team 2(ì •ë³´ ê²€ìƒ‰)ê°€ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” **ë¼ìš°íŒ… í•¨ìˆ˜**ì…ë‹ˆë‹¤.
    """
    print("--- ROUTER: ì •ë³´ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨ ---")
    
    if state.get("status", {}).get("team1") == "fail":
        print("ğŸš¦ ë¼ìš°í„°: Team 1 ì‹¤íŒ¨ ê°ì§€. ì›Œí¬í”Œë¡œìš°ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return END

    question = state.get("q_en_transformed", "")
    
    prompt = PromptTemplate.from_template("""
You are a meticulous and safety-conscious router in a Q&A pipeline. Your critical task is to determine if a user's question can be answered *reliably* with your general knowledge, or if it requires consulting specific, external information to ensure accuracy and currency.

Your response must be a single word: either 'retrieve' or 'skip'.

**Decision Criteria:**

1.  **retrieve**: Choose this if the question involves any of the following:
    * **Specific Products/Services:** Mentions specific models, brands, software versions (e.g., "ASUS Z790 motherboard", "Photoshop 2024", "LangGraph v0.1").
    * **Technical Procedures:** Asks for step-by-step instructions, troubleshooting, or "how-to" guides (e.g., "How to replace a CPU?", "My code is throwing a NullPointerException").
    * **Recent Events or Data:** Refers to events after your last knowledge update or requires real-time information (e.g., "What were the latest tech stock trends this week?").
    * **Safety-Critical Information:** Answering incorrectly could have negative consequences (e.g., medical advice, financial guidance, hardware modifications).
    * **Comparisons or Recommendations:** Asks for the "best" product, comparisons between items, or specific recommendations.

2.  **skip**: Choose this *only* for questions that are definitively answerable with universal, timeless general knowledge.
    * **General Knowledge:** "What is the capital of France?", "Explain the theory of relativity."
    * **Simple Greetings & Conversations:** "Hello", "How are you?"
    * **Basic Math or Logic:** "What is 5 + 7?"
    * **Creative Writing or Brainstorming:** "Write a poem about the sea."

**Your thought process:**
First, analyze the user's question for keywords related to products, technical actions, or time-sensitive topics.
Second, evaluate the risk of providing an outdated or incorrect answer based on general knowledge alone. If there is any risk, err on the side of caution.
Finally, conclude with 'retrieve' or 'skip'.

**When in doubt, always choose 'retrieve'.**

Question: "{question}"
""").partial(question=question)

    llm = ChatOpenAI(model=config.LLM_MODEL_SUPER_ROUTER, temperature=0.0)
    chain = prompt | llm | StrOutputParser()
    
    try:
        decision = chain.invoke({})
        print(f"ğŸ§  ë¼ìš°í„° LLM ê²°ì •: '{decision}'")
        if "retrieve" in decision.lower():
            print("ğŸš¦ ë¼ìš°í„°: ì •ë³´ ê²€ìƒ‰ í•„ìš”. Team 2ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            return "team2"
        else:
            print("ğŸš¦ ë¼ìš°í„°: ì •ë³´ ê²€ìƒ‰ ë¶ˆí•„ìš”. Team 2ë¥¼ ê±´ë„ˆë›°ê³  Team 3ë¡œ ì´ë™í•©ë‹ˆë‹¤.")
            state["status"]["team2"] = "pass"
            return "team3"
    except Exception as e:
        print(f"âŒ ë¼ìš°í„° LLM ì‹¤í–‰ ì˜¤ë¥˜: {e}. ì•ˆì „í•˜ê²Œ Team 2ë¡œ ë³´ëƒ…ë‹ˆë‹¤.")
        return "team2"

def create_super_graph(team1_app, team2_app, team3_app):
    """
    ì§€ëŠ¥í˜• ë¼ìš°í„°ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë“  íŒ€ ì„œë¸Œê·¸ë˜í”„ë¥¼ í†µí•©í•©ë‹ˆë‹¤.
    """
    builder = StateGraph(GlobalState)

    # 1. ê° íŒ€ ì„œë¸Œê·¸ë˜í”„ë¥¼ ë…¸ë“œë¡œ ì¶”ê°€í•©ë‹ˆë‹¤.
    builder.add_node("team1", team1_app)
    builder.add_node("team2", team2_app)
    builder.add_node("team3", team3_app)

    # 2. ì—£ì§€ë¥¼ ì—°ê²°í•©ë‹ˆë‹¤.
    builder.set_entry_point("team1")
    
    builder.add_conditional_edges(
        "team1", # ì‹œì‘ ë…¸ë“œ
        retrieval_necessity_router, # íŒë‹¨ í•¨ìˆ˜
        { # íŒë‹¨ ê²°ê³¼ì— ë”°ë¥¸ ë¶„ê¸°
            "team2": "team2",
            "team3": "team3",
            END: END
        }
    )
    
    builder.add_edge("team2", "team3")
    builder.add_edge("team3", END)

    # 3. ìµœì¢… ê·¸ë˜í”„ë¥¼ ì»´íŒŒì¼í•©ë‹ˆë‹¤.
    return builder.compile()
