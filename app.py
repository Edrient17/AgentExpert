# app.py
import os
import streamlit as st
from langchain_core.tracers import LangChainTracer
from dotenv import load_dotenv
from main_graph import graph

load_dotenv()
tracer = LangChainTracer(project_name=os.getenv("LANGCHAIN_PROJECT", "AgentExpert"))

# === ì´ˆê¸°í™” ===
st.set_page_config(page_title="LangGraph RAG QA", layout="wide")
st.title("LangGraph ê¸°ë°˜ ì§ˆë¬¸ ì‘ë‹µ ì‹œìŠ¤í…œ")

# === ì…ë ¥ ë°›ê¸° ===
user_input = st.text_area("ğŸ’¬ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", height=100)

if st.button("ì§ˆë¬¸ ì‹¤í–‰"):
    if not user_input.strip():
        st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):

            # === ìƒíƒœ ì´ˆê¸°í™” ===
            initial_state = {
                # ì…ë ¥
                "user_input": user_input.strip(),

                # ê¸°ë³¸ê°’
                "q_validity": True,
                "q_en_transformed": "",
                "rag_queries": [],
                "rag_query": "",
                "rag_query_scores": [],
                "output_format": ["qa", "ko"],

                # í›„ì† ë‹¨ê³„
                "rag_docs": [],
                "web_docs": [],
                "generated_answer": "",

                # ì—ëŸ¬/ì œì–´
                "error_message": "",
                "status": {"team1": "", "team2": "", "team3": ""},
                "next_node": "team1_supervisor",
            }

            # === LangGraph ì‹¤í–‰ ===
            result = graph.invoke(initial_state)

        # === ì—ëŸ¬ í‘œì‹œ or ìµœì¢… ë‹µë³€ í‘œì‹œ ===
        if result.get("error_message"):
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.: {result['error_message']}")
        else:
            st.subheader("ğŸ§¾ ìµœì¢… ë‹µë³€")
            answer = result.get("generated_answer", "").strip()
            st.markdown(answer or "_ìƒì„±ëœ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤._")

        # === ë‚´ë¶€ ìƒíƒœ (ë””ë²„ê¹…ìš©) ===
        st.divider()
        with st.expander("ğŸ§© ì „ì²´ ìƒíƒœ ë³´ê¸° (ë””ë²„ê¹…)"):
            st.json(result)
